{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "LSTMprediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshat-Tripathi/AIHack20/blob/master/LSTMprediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLmKthlsuBRZ",
        "colab_type": "text"
      },
      "source": [
        "# Compressor Analytics Dataset\n",
        "\n",
        "Below are a few things to get you started with the Compressor Analytics dataset for AIHack! For more information see [here](https://drive.google.com/file/d/1ojYVHpabfkNz45nQqQLenyoaQbCmWdo4/view?usp=sharing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH1UeoJNuBRf",
        "colab_type": "code",
        "outputId": "644968df-046d-43f1-b18e-db4497efb1e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Download data - please only run this once\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"Starting download ...\")\n",
        "urls = [\n",
        "    \"https://github.com/aihack20/shell_challenge/releases/download/data/clean_dataset.zip\",\n",
        "    \"https://github.com/aihack20/shell_challenge/releases/download/data/raw_dataset.zip\",\n",
        "]\n",
        "os.makedirs(\"shell_data\", exist_ok=True)\n",
        "for url in urls:\n",
        "    with urllib.request.urlopen(url) as src:\n",
        "        with open(\"tmp.zip\", \"wb\") as dest:\n",
        "            dest.write(src.read())\n",
        "    print(\"Unpacking archive ...\")\n",
        "    with zipfile.ZipFile(\"tmp.zip\") as f:\n",
        "        f.extractall(\"shell_data\")\n",
        "print(\"Done!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting download ...\n",
            "Unpacking archive ...\n",
            "Unpacking archive ...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yzRNgXOuBSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqBu_suiuBSY",
        "colab_type": "code",
        "outputId": "0a0662ed-25eb-40f7-d067-27bd897347eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Load the data (will take a short while)\n",
        "clean_data = pd.read_csv(\"shell_data/clean_dataset.csv\")\n",
        "raw_data = pd.read_csv(\"shell_data/raw_dataset.csv\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K68iQSZ8uBSi",
        "colab_type": "text"
      },
      "source": [
        "## Your Hack ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKt5D-oYuBSm",
        "colab_type": "code",
        "outputId": "2d5e057a-8ae4-4cdf-a12d-6cab3b1b39a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbp2xzA7uBSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(clean_data.dropna())\n",
        "# df = pd.DataFrame(clean_data)\n",
        "heads = list(df)\n",
        "\n",
        "hold = df.to_numpy()\n",
        "df_shape = df.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBkkt8uFv4gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "hold_norm = scaler.fit_transform(hold)\n",
        "\n",
        "ts = 60\n",
        "\n",
        "\n",
        "# nan_arr = np.argwhere(np.isnan(hold))\n",
        "# hold_nom = hold_norm[~np.isnan(hold_norm).any(axis=1)]\n",
        "\n",
        "# nan_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "983nNP4q504u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A list of time periods (also a list) where is each element is a row of dataframe --> [[index]]\n",
        "values = clean_data.values\n",
        "last_index = 0\n",
        "current_period = [0]\n",
        "periods = []\n",
        "\n",
        "for i in range(1,len(values)):\n",
        "  if last_index == clean_data.iloc[i]['original_index'] - 1:\n",
        "    current_period.append(i)\n",
        "    last_index+=1\n",
        "  else:\n",
        "    periods.append(current_period)\n",
        "    current_period = [i]\n",
        "    last_index = clean_data.iloc[i]['original_index']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAVoDToA6SBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting all data for now, also for digital twin\n",
        "\n",
        "\n",
        "goodc = []\n",
        "\n",
        "for i in periods:\n",
        "  if len(i) > ts:\n",
        "    goodc.append(i[:-ts])\n",
        "\n",
        "\n",
        "from itertools import chain\n",
        "goodcc = list(chain.from_iterable(goodc))\n",
        "\n",
        "\n",
        "x_all = np.empty([len(goodcc), ts, df_shape[1]])\n",
        "y_all = np.empty([len(goodcc), df_shape[1]])\n",
        "\n",
        "\n",
        "for i, j in enumerate(goodcc):\n",
        "  y_all[i] = hold_norm[j+ts]\n",
        "  for k in range(ts):\n",
        "    x_all[i][k] = hold_norm[j+k]\n",
        "\n",
        "train_len = math.ceil(len(y_all)*0.8)\n",
        "x_test = x_all[train_len:]\n",
        "y_test = y_all[train_len:]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDhDWNm0O9Jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "solvers = ['adam','SGD','RMSprop','Adagrad','Adadelta','Adamax','Nadam']\n",
        "losses = ['mean_squared_error','mean_absolute_error','mean_absolute_percentage_error',\n",
        "          'mean_squared_logarithmic_error','squared_hinge','hinge','categorical_hinge',\n",
        "          'logcosh','huber_loss','categorical_crossentropy','sparse_categorical_crossentropy',\n",
        "          'binary_crossentropy', 'kullback_leibler_divergence','poisson','cosine_proximity',\n",
        "          'is_categorical_crossentropy']\n",
        "n = 0\n",
        "tries  = [[] for i in range(len(solvers)*len(losses))]\n",
        "for x in solvers:\n",
        "  for y in losses:\n",
        "    tries[n] = [x,y,x+'-'+y]\n",
        "    n += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fAqzOvtFDlo",
        "colab_type": "code",
        "outputId": "a8eaa369-2622-4ec4-843d-648b5f34d913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import keras\n",
        "directory = os.listdir('/content/gdrive/My Drive/nets/')\n",
        "\n",
        "\n",
        "h5files = []\n",
        "txts = []\n",
        "for x in directory:\n",
        "  if x.endswith('.h5'):\n",
        "    h5files.append(x)\n",
        "  elif x.endswith('.txt'):\n",
        "    txts.append(x)\n",
        "\n",
        "\n",
        "accs = []\n",
        "errors = []\n",
        "loses = []\n",
        "for i,x in enumerate(txts):\n",
        "  # i = 1  # remove for actual run\n",
        "  # x = txts[i]  # remove for actual run\n",
        "  print(x)\n",
        "  f = open(F'/content/gdrive/My Drive/nets/' + x, 'r')\n",
        "  try:\n",
        "    h = f.readlines()[0].strip('][').split(', ')\n",
        "  except IndexError:\n",
        "    continue\n",
        "  j = [float(x) for x in h]\n",
        "  errors.append(j)\n",
        "\n",
        "  fileh5 = F'/content/gdrive/My Drive/nets/' + h5files[i]\n",
        "\n",
        "  new_model = keras.models.load_model(fileh5)\n",
        "  # new_model.summary()\n",
        "\n",
        "  acc = new_model.evaluate(x_test, y_test)\n",
        "  accs.append(acc)\n",
        "\n",
        "  print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adam-binary_crossentropy.txt\n",
            "19958/19958 [==============================] - 23s 1ms/step\n",
            "Restored model, accuracy: 254.30%\n",
            "adam-kullback_leibler_divergence.txt\n",
            "19958/19958 [==============================] - 24s 1ms/step\n",
            "Restored model, accuracy: 82822.26%\n",
            "adam-cosine_proximity.txt\n",
            "adam-poisson.txt\n",
            "19958/19958 [==============================] - 23s 1ms/step\n",
            "Restored model, accuracy: -99.12%\n",
            "adam-mean_squared_error.txt\n",
            "19958/19958 [==============================] - 23s 1ms/step\n",
            "Restored model, accuracy:  0.76%\n",
            "SGD-mean_squared_error.txt\n",
            "19958/19958 [==============================] - 24s 1ms/step\n",
            "Restored model, accuracy: 24.42%\n",
            "RMSprop-mean_squared_error.txt\n",
            "19958/19958 [==============================] - 24s 1ms/step\n",
            "Restored model, accuracy:  0.86%\n",
            "Adagrad-mean_squared_error.txt\n",
            "19958/19958 [==============================] - 25s 1ms/step\n",
            "Restored model, accuracy:  1.10%\n",
            "Adadelta-mean_squared_error.txt\n",
            "19958/19958 [==============================] - 25s 1ms/step\n",
            "Restored model, accuracy:  1.15%\n",
            "Adamax-mean_squared_error.txt\n",
            "19958/19958 [==============================] - 26s 1ms/step\n",
            "Restored model, accuracy:  0.97%\n",
            "Nadam-mean_squared_error.txt\n",
            "19958/19958 [==============================] - 26s 1ms/step\n",
            "Restored model, accuracy:  0.89%\n",
            "adam-mean_absolute_error.txt\n",
            "19958/19958 [==============================] - 28s 1ms/step\n",
            "Restored model, accuracy:  4.75%\n",
            "SGD-mean_absolute_error.txt\n",
            "19958/19958 [==============================] - 26s 1ms/step\n",
            "Restored model, accuracy: 40.05%\n",
            "RMSprop-mean_absolute_error.txt\n",
            "19958/19958 [==============================] - 27s 1ms/step\n",
            "Restored model, accuracy:  6.17%\n",
            "Adagrad-mean_absolute_error.txt\n",
            "19958/19958 [==============================] - 27s 1ms/step\n",
            "Restored model, accuracy:  6.13%\n",
            "Adadelta-mean_absolute_error.txt\n",
            "19958/19958 [==============================] - 28s 1ms/step\n",
            "Restored model, accuracy:  9.65%\n",
            "Adamax-mean_absolute_error.txt\n",
            "19958/19958 [==============================] - 27s 1ms/step\n",
            "Restored model, accuracy:  5.11%\n",
            "Nadam-mean_absolute_error.txt\n",
            "19958/19958 [==============================] - 28s 1ms/step\n",
            "Restored model, accuracy:  6.41%\n",
            "adam-mean_absolute_percentage_error.txt\n",
            "19958/19958 [==============================] - 30s 1ms/step\n",
            "Restored model, accuracy: 15307351.69%\n",
            "SGD-mean_absolute_percentage_error.txt\n",
            "19958/19958 [==============================] - 28s 1ms/step\n",
            "Restored model, accuracy:   nan%\n",
            "RMSprop-mean_absolute_percentage_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy: 17442177.83%\n",
            "Adagrad-mean_absolute_percentage_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy: 30624218.82%\n",
            "Adadelta-mean_absolute_percentage_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy: 23115522.80%\n",
            "Adamax-mean_absolute_percentage_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy: 31449453.32%\n",
            "Nadam-mean_absolute_percentage_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy: 28102983.81%\n",
            "adam-mean_squared_logarithmic_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy:  4.99%\n",
            "SGD-mean_squared_logarithmic_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy: 13.90%\n",
            "RMSprop-mean_squared_logarithmic_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy:  4.90%\n",
            "Adagrad-mean_squared_logarithmic_error.txt\n",
            "19958/19958 [==============================] - 29s 1ms/step\n",
            "Restored model, accuracy:  4.78%\n",
            "Adadelta-mean_squared_logarithmic_error.txt\n",
            "19958/19958 [==============================] - 30s 2ms/step\n",
            "Restored model, accuracy: 10.39%\n",
            "Adamax-mean_squared_logarithmic_error.txt\n",
            "19958/19958 [==============================] - 30s 1ms/step\n",
            "Restored model, accuracy:  6.05%\n",
            "Nadam-mean_squared_logarithmic_error.txt\n",
            "19958/19958 [==============================] - 30s 1ms/step\n",
            "Restored model, accuracy:  5.03%\n",
            "adam-squared_hinge.txt\n",
            "19958/19958 [==============================] - 30s 1ms/step\n",
            "Restored model, accuracy:  3.85%\n",
            "SGD-squared_hinge.txt\n",
            "19958/19958 [==============================] - 30s 1ms/step\n",
            "Restored model, accuracy: 50.89%\n",
            "RMSprop-squared_hinge.txt\n",
            "19958/19958 [==============================] - 32s 2ms/step\n",
            "Restored model, accuracy:  3.35%\n",
            "Adagrad-squared_hinge.txt\n",
            "19958/19958 [==============================] - 30s 1ms/step\n",
            "Restored model, accuracy:  3.90%\n",
            "Adadelta-squared_hinge.txt\n",
            "19958/19958 [==============================] - 31s 2ms/step\n",
            "Restored model, accuracy:  4.24%\n",
            "Adamax-squared_hinge.txt\n",
            "19958/19958 [==============================] - 31s 2ms/step\n",
            "Restored model, accuracy:  3.92%\n",
            "Nadam-squared_hinge.txt\n",
            "19958/19958 [==============================] - 31s 2ms/step\n",
            "Restored model, accuracy:  3.77%\n",
            "adam-hinge.txt\n",
            "19958/19958 [==============================] - 31s 2ms/step\n",
            "Restored model, accuracy:  3.92%\n",
            "SGD-hinge.txt\n",
            "19958/19958 [==============================] - 31s 2ms/step\n",
            "Restored model, accuracy: 78.90%\n",
            "RMSprop-hinge.txt\n",
            "19958/19958 [==============================] - 31s 2ms/step\n",
            "Restored model, accuracy:  3.41%\n",
            "Adagrad-hinge.txt\n",
            "19958/19958 [==============================] - 31s 2ms/step\n",
            "Restored model, accuracy:  3.97%\n",
            "Adadelta-hinge.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bbaa1dfeeae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;31m# new_model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0maccs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1298\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                                          \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                          callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     def predict(self, x,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2931\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2932\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2933\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2934\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2883\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2885\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2886\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1502\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \"\"\"\n\u001b[0;32m-> 1504\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-87g07xdLVq",
        "colab_type": "code",
        "outputId": "954fe54a-8618-4ad6-991d-50aa34ff2430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "# predict_test = np.empty([x_test.shape[0],x_test.shape[1],x_test.shape[2]])\n",
        "predict_test = np.empty([x_test.shape[0],x_test.shape[1],x_test.shape[2]])\n",
        "\n",
        "\n",
        "for i,j in enumerate(h5files):\n",
        "  fileh5 = F'/content/gdrive/My Drive/nets/' + h5files[i]\n",
        "  h = x_test[0]\n",
        "  h = np.reshape(h,[1,h.shape[0],h.shape[1]])\n",
        "  \n",
        "  new_model = keras.models.load_model(fileh5)\n",
        "  print(j)\n",
        "  for i, j in enumerate(predict_test):\n",
        "    if i == 0:\n",
        "      predict_test[i] = x_test[0]\n",
        "    else:\n",
        "      h[0] = predict_test[i-1]\n",
        "      p = new_model.predict(h)\n",
        "      h[0][:-1] = h[0][1:]\n",
        "      h[0][-1] = p\n",
        "      predict_test[i] = h\n",
        "      \n",
        "\n",
        "  los = new_model.evaluate(predict_test,y_test)\n",
        "  print(los)\n",
        "  loses.append(los)\n",
        "\n",
        "\n",
        "# for x in range()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adam-binary_crossentropy.h5\n",
            "19958/19958 [==============================] - 32s 2ms/step\n",
            "2.545197690341979\n",
            "adam-kullback_leibler_divergence.h5\n",
            "19958/19958 [==============================] - 32s 2ms/step\n",
            "828.2226455157883\n",
            "adam-poisson.h5\n",
            "19958/19958 [==============================] - 32s 2ms/step\n",
            "nan\n",
            "adam-cosine_proximity.h5\n",
            "19958/19958 [==============================] - 33s 2ms/step\n",
            "-0.9484322290045906\n",
            "adam-mean_squared_error.h5\n",
            "19958/19958 [==============================] - 32s 2ms/step\n",
            "0.017834835426430388\n",
            "SGD-mean_squared_error.h5\n",
            "19958/19958 [==============================] - 33s 2ms/step\n",
            "0.4111565647598067\n",
            "RMSprop-mean_squared_error.h5\n",
            "19958/19958 [==============================] - 33s 2ms/step\n",
            "0.010819657935778368\n",
            "Adagrad-mean_squared_error.h5\n",
            "19958/19958 [==============================] - 33s 2ms/step\n",
            "0.013343929691569266\n",
            "Adadelta-mean_squared_error.h5\n",
            "19958/19958 [==============================] - 33s 2ms/step\n",
            "0.011922421294649661\n",
            "Adamax-mean_squared_error.h5\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}